# アーキテクチャ

(WIP)

(**HAM** は `hsp3-analyzer-mini` 自身のこと)

これは「HAMのコードベースへの理解」を助けることを目的として書かれている

## 前提知識

- HSP、HAMの基本的な使いかた
- インタプリタまたはコンパイラの基本的な仕組み、作りかた
- ほか

## アナライザ

- HAMのようなソフトウェアを **アナライザ** (analyzer) と呼ぶことにする
- アナライザは言語処理系の一種で、エディタ内でのホバー表示や入力補完などの機能を提供するソフトウェアである
- アナライザが提供するそれらの機能を総称的に **IDE機能** と呼ぶことにする

### アナライザの入出力

- アナライザは **入力** としてスクリプトと、そのスクリプトの意味に関する質問を受け取り、質問への回答を **出力** するものである
- 例:
    - ホバー表示でいえば、質問は「`main.hsp` の8行目・4文字目にある `foo` という単語は何？」といったもの
    - アナライザは「この `foo` はdeffuncで定義された命令である」と応答できる
- アナライザはスクリプトに関する問い合わせシステムであるといえる

### LSP

- **LSP** (language server protocol) はエディタ (VSCode) とアナライザをつなぐための仕組み
- ユーザーの操作によって、エディタはIDE機能を作動させる。エディタはその処理のためにアナライザに問い合わせを行う
    - (エディタにプログラミング言語固有の機能を持たせるわけにはいかないため)
- LSPという仕様では、エディタがアナライザにどう問い合わせるか、アナライザがそれにどう応答するか、を定められている

----

## HAMの内部構造

- HAMの内部構造は大きく分けて以下のパーツからなる
    - 字句解析・構文解析
    - 意味解析
    - データベースレイヤー
    - IDE機能
    - LSPサーバー

### 字句解析・構文解析

- (ここはインタプリタやコンパイラと同様)
- スクリプトを **字句解析** (tokenize) してトークン列 (tokens) に変換する
- トークン列を **構文解析** (parse) して **解析木** (parse tree) に変換する
- IDE機能に使うため、位置情報 (location) を正確に保持している

### 意味解析

- (ここはインタプリタやコンパイラと同様)
- 解析木に **意味解析** を行い、**シンボル** (symbol) や **スコープ** (scope) の情報を収集する
    - **シンボル** (symbol) はスクリプト内で定義されている名前のこと (変数やラベル、命令など)

### データベースレイヤー

- (これは仮の呼称。このパーツのことを何と呼ぶべきか分からない)
- HAMは実行中に以下の2つのデータを保持している
- 1つ目:
    - HAMが扱うスクリプトは、ファイルに保存されているものと、エディタ内で編集中のものがある。これらを総称して **ドキュメント** (document) と呼ぶ
    - HAMは全ドキュメントのデータを保持している
        - ファイルの内容を保持しているのは、ファイルの読み込みにかかる時間を省くため
        - 「エディタ内の編集中のデータ」は、アナライザから問い合わせて取得することができず、エディタから送られてくるものであるため
- 2つ目:
    - 解析結果を表すデータ構造を **アナリシス** (analysis) と呼んでいる
    - HAMは意味解析の結果の一部をキャッシュとして保持している。これは効率を改善するため
- 効率の話:
    - エディタ上でキー入力されるたびに、スクリプトの変更とIDE機能の処理要求が発生する。これはかなりの高頻度である
    - 一連の解析処理を毎回、最初から行うのは非効率である。たいていの場合、スクリプトの変更は1行の追加や削除で、解析処理の大部分は変化しないため
    - 解析処理の結果を記憶 (キャッシュ) しておき、変更の影響を受けなかった部分の再解析をある程度防ぐように、データ構造が設計されている

### IDE機能

- アナリシスを使って、ホバー表示や入力補完などの個別のIDE機能が実装されている

### LSPサーバー

- **LSPサーバー** (LSP server) は、LSP仕様にしたがって動作するプロセスで、エディタとアナライザが対話するためのもの

----

## ウォークスルー

実行時の流れを時系列に沿って軽く述べる

### 1. 初期化

はじめに初期化が行われる

- エディタ(VSCode)によってHAMの拡張機能が起動(activate)され、そのLSPクライアントがLSPサーバープロセスを起動する
- LSPの仕様にしたがって、エディタがサーバーに `initialize` リクエストを送り、サーバーがレスポンスを返す
- サーバーは初期データの読み込みを行う (common, hsphelp, ワークスペース内のスクリプト)

#### 2. (例1) `references`

エディタでシンボルにカーソルを合わせ、「すべての参照を検索」を行ったとする

- エディタがサーバーに `references` リクエストを送る (ドキュメントのURIと行番号・列番号が含まれる)
- サーバーがそのリクエストを受け取り、`lsp_handler` で `text_document_references` 関数が呼ばれる
- 処理の本体は `assists/references.rs` にある
- 指定したドキュメントに関連するプロジェクトの解析結果 (ProjectAnalysis) を取得する
    - このときプロジェクトに対して解析処理が行われる
        (この解析結果は次にそのプロジェクトに変更があるまで保持される)
- そのドキュメントの指定された位置にあるシンボルを特定する (`locate_symbol`)
    - プロジェクト内にある全シンボルのすべての定義箇所、使用箇所は解析結果に含まれている。
        これらの中から指定位置にあるものを探す
- このシンボルの使用箇所の列挙を行う
    - 解析結果が持っている使用箇所の一覧を、そのシンボルで絞り込めばいい
    - (`references` の具体的な挙動はほかにもあるかもしれないが、ここでは省略)
- 最後に収集したデータをLSP仕様に沿うかたちに変換して返す
- `lsp_handler` がそのデータをレスポンスとしてエディタに送る

#### 3. (例2) `didChange`

エディタで編集中のスクリプトにキー入力をしたとする

- エディタがドキュメントの変更 (`didChange`) をサーバーに送る
- サーバーはそのリクエストを受け取って、`lsp_handler` で `text_document_did_change` 関数が呼ばれる
- `docs` (ドキュメントストア) に変更後のデータが記録される
    - この時点では再解析は行われない
    - この変更によって再解析が必要となるデータの解析結果が削除される
    - 次に (`references` などのリクエストで) プロジェクトの解析結果が必要となったときに、あらためて解析が行われる

#### 4. 終了

エディタが閉じるときなどに終了処理が行われる。
LSPサーバーが終了時に行う処理は特にないため、この流れはあまり重要ではない

- エディタが拡張機能を停止(deactivate)し、そこでLSPクライアントが停止される
- LSPの仕様により、まずクライアントはLSPサーバーに `shutdown` リクエストを送る
    - LSPサーバーが `shutdown` リクエストにレスポンスする (サーバー側では特に何も起きない)
- クライアントが `exit` 通知を送り、サーバーが自発的に終了する

----

## その他

(以下、分かりやすいかどうかはともかく、どこかには書かないといけないことをトピックごとに書いてある)

### プロジェクト

- `include` によって結合される一連のファイルを **プロジェクト** (project) と呼ぶことにしている
    (EDIT: この定義は取り下げるかもしれない)
- アナライザが扱う全体のことを **ワークスペース** (workspace) と呼ぶことにしている
- データベースレイヤーのアナリシスは、ドキュメントごと、プロジェクトごと、ワークスペースごとに、解析結果のデータを分割して持っている
    (`DocAnalysis`, `ProjectAnalysis`, `WorkspaceAnalysis`)
    - スクリプトの変更の際に、そのスクリプト以外のドキュメントごとの解析結果は影響を受けないので、再解析を省ける。プロジェクトについても同様。(ワークスペースは常に影響を受ける)

### `common`

- HSPのインストールフォルダに `common` フォルダがあり、ここに標準のモジュールなどが置かれている
- HAMは起動時にこれらのスクリプトをすべて収集している
    - アナライザへの入力の一部とみなされる

### `hsphelp`

- HSPのインストールフォルダに `hsphelp` フォルダがあり、ここに組み込み命令の説明などが書かれた **ヘルプファイル** (.hs) がある。
    スクリプトエディタで「F1」キーを押すと表示される説明やサンプルはこれらのファイルがもとになっている。
    詳細はHSPのインストールフォルダの `doclib/HSP Doc Library` にあるファイルを参照
- HAMは起動時にヘルプファイルをすべて収集している
    - アナライザへの入力の一部とみなされる
    - シグネチャヘルプの実装に使われている

### トリビアトークン

- HAMの字句解析では、空白やコメントもトークンとみなす。これらのトークンを **トリビア** (trivia) と呼んでいる
    - 文脈: 典型的なコンパイラの教科書では空白やコメントをトークンとみなさない。コンパイラはコメントを無視するのでそれでいい
    - 理由: アナライザでは、コメントに書かれている内容を後で参照したり、コードアクション (スクリプトの内容の変更を提案する操作) があるため、念のためトークンとして残している (これはrust-analyzerの設計を参考にした)
- HAMの構文解析では、構文トークン (`PToken`) という概念を導入する
    - 理由: トークン列の中にトリビアが挟まっていると、構文解析の先読みで邪魔になる
    - トリビアとその周囲のトークンをまとめて1個の構文トークンに固める
        - これによって構文解析中の先読みにトリビアは影響しなくなる

### パーサー

- 手書きの再帰下降構文解析 (LL法) を使っている
- プリプロセッサ (`#` のある行) とそれ以外 (地の文) を分けずにパースしている
- 演算子の結合 (優先順位) を無視している
    - いま実装済みのIDE機能においては支障がないはず
- うまくパースできない場面があり、適当なヒューリスティック (厳密には誤っているが、実際に与えられるスクリプトに対してはたいていうまくいくだろう方法) でしのいでいる
    - 名前が命令として定義済みかどうかで曖昧になることがあるため

----

## 課題など

### マクロ機能がないこと

マクロ機能を実装する上で「エントリーポイントが未確定であること」という課題がある

- マクロ機能は「上から下へ」解析する必要がある
    - マクロの定義は `#define` によって追加され、`#undef` によって消される
    - `#if` などの分岐の解釈は、その時点で定義されているマクロによる
    - ファイルは `#include` によって結合して使われることがある。その場合、そのincludeの使用箇所において定義されているマクロが、そのスクリプトファイルの先頭においても定義されていることになる
        - 同じスクリプトファイルが複数個所でincludeされていて、そこで定義されているマクロが異なるおそれがある
- 直接実行されるスクリプトを **エントリーポイント** (入口) と呼ぶことにする
    - スクリプトエディタで開いて F5 (実行) を押すときのファイルのこと
    - 一方、それ以外のファイルは `#include` などの命令によって間接的に使用される
- ファイルを開いていてIDE機能を使う時点で、どのスクリプトがエントリーポイントであるかは確定していない
    - そのスクリプト自身がエントリーポイントかもしれない。
        ほかのスクリプトを実行するときに間接的にincludeされるのかもしれない
    - エントリーポイントは複数ありうる
        (例えば汎用的なモジュールがあって、それをアプリAとアプリBの両方からincludeする状況はありうる)
        - この状況で `rename` や `references` などの「シンボルの使用箇所を検索する」機能の結果には、アプリA/B両方が含まれるはず
- 単純な解決策は、すべてのスクリプトをエントリーポイントとみなして、そこから解析を行うこと
    - それぞれのスクリプトについて、それをエントリーポイントであると仮定して解析を行う
        - 一連の解析にはincludeによって複数のスクリプトが含まれうる。
            逆にいうと、スクリプトファイルごとに、それを解析中に使うようなエントリーポイントは複数ありうる
    - 特定のファイルに対してIDE機能を使うとする。
        この時点で、そのファイルを解析に含むことになるエントリーポイントが複数ありうる
        - それぞれのエントリーポイントごとにIDE機能の解析処理を適用して、その結果から冗長性を取り除いて集約する
    - (課題):
        - 結果を集約する方法を検討する必要がある
        - 計算コストが高そうにみえる (測ってはいない)
    - `diagnose` をどうするのか
        - ユーザーが想定していないエントリーポイントでは、シンボルが未定義などのエラーが発生することが多い。
        これらのエラーは報告しても意味がない
        (いま実装済みの診断については問題ないかもしれない)
- 計算量的にスマートだが不正確な解決策の一案:
    ファイル間の `include` の流れをあらかじめ計算する。
    IDE機能の対象となるファイルからさかのぼって、それを間接的にincludeする可能性があるエントリーポイントを列挙する。
    それぞれのエントリーポイントからマクロ展開処理を行って、実際に指定ファイルをincludeしたものを選別し、それぞれにIDE機能を適用して、結果を集約する
    - 結局、結果を集約する方法を検討する必要がある
    - `include` のファイル名がマクロで指定されていると解決が不可能なので、諦めることになる

例:

```hsp
; file: mod_x.hsp
#ifdef DEFINE_A
    #deffunc a
#else
    #deffunc b
#endif

; file: a.hsp
#define DEFINE_A
#include "mod_x.hsp"  ; defines a

; file: b.hsp
#include "mod_x.hsp"  ; defines b
```

----

> [ARCHITECTURE.md](https://matklad.github.io/2021/02/06/ARCHITECTURE.md.html)
